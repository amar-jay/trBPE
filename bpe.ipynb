{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb682125-a4ee-48b9-a6d7-bb4a500a8dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ea0edf-8adb-44e6-b446-d96406f75817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TurkishStemmer import TurkishStemmer\n",
    "from trBPE.core import visualise_tokens, turkish_word_splitter, turkish_split\n",
    "import base64\n",
    "import os\n",
    "from _tiktoken import train_simple_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41d02b1-c2b7-41ab-af01-e22411954c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current most common pair is b' ' + b'ip'\n",
      "So we made b' ip' our 600th token\n",
      "Now the first fifty words in our training data look like:\n",
      "\u001b[48;5;167mBut\u001b[48;5;77m I\u001b[48;5;68m m\u001b[48;5;167must\u001b[48;5;77m expl\u001b[48;5;179main\u001b[48;5;80m to\u001b[48;5;167m you\u001b[48;5;80m how\u001b[48;5;179m al\u001b[48;5;80ml\u001b[48;5;68m this\u001b[48;5;77m m\u001b[48;5;68mis\u001b[48;5;167mtak\u001b[48;5;77men\u001b[48;5;68m id\u001b[48;5;179mea\u001b[48;5;77m of\u001b[48;5;134m denoun\u001b[48;5;167mc\u001b[48;5;179ming\u001b[48;5;77m pleasure\u001b[48;5;68m and\u001b[48;5;185m pra\u001b[48;5;134mis\u001b[48;5;179ming\u001b[48;5;80m pain\u001b[48;5;185m w\u001b[48;5;80mas\u001b[48;5;134m b\u001b[48;5;179mor\u001b[48;5;77mn\u001b[48;5;80m and\u001b[48;5;179m I\u001b[48;5;77m will\u001b[48;5;179m g\u001b[48;5;77mi\u001b[48;5;80mve\u001b[48;5;134m you\u001b[48;5;77m a\u001b[48;5;68m com\u001b[48;5;185mple\u001b[48;5;68mte\u001b[48;5;167m acc\u001b[48;5;80mount\u001b[48;5;179m of\u001b[48;5;80m the\u001b[48;5;179m s\u001b[48;5;77my\u001b[48;5;80mst\u001b[48;5;134mem\u001b[48;5;179m,\u001b[48;5;185m and\u001b[48;5;134m exp\u001b[48;5;77mound\u001b[48;5;167m the\u001b[48;5;80m a\u001b[48;5;134mct\u001b[48;5;179mu\u001b[48;5;185mal\u001b[48;5;80m t\u001b[48;5;134mea\u001b[48;5;179mc\u001b[48;5;185mh\u001b[48;5;77ming\u001b[48;5;134ms\u001b[48;5;167m of\u001b[48;5;77m the\u001b[48;5;167m great\u001b[48;5;134m expl\u001b[48;5;80more\u001b[48;5;167mr\u001b[48;5;179m of\u001b[48;5;80m the\u001b[48;5;179m t\u001b[48;5;77mr\u001b[48;5;80mut\u001b[48;5;134mh\u001b[48;5;167m,\u001b[48;5;179m the\u001b[48;5;68m m\u001b[48;5;167mas\u001b[48;5;185mter\u001b[48;5;68m-\u001b[48;5;134mb\u001b[48;5;167mu\u001b[48;5;179mil\u001b[48;5;77md\u001b[48;5;80mer\u001b[48;5;134m of\u001b[48;5;185m h\u001b[48;5;80mum\u001b[48;5;134man\u001b[48;5;179m ha\u001b[48;5;80mp\u001b[48;5;68mp\u001b[48;5;134miness\u001b[48;5;80m.\u001b[48;5;68m No\u001b[48;5;179m one\u001b[48;5;68m rejects\u001b[48;5;134m,\u001b[48;5;167m dislik\u001b[48;5;179mes\u001b[48;5;185m,\u001b[48;5;77m or\u001b[48;5;134m avoids\u001b[48;5;167m pleasure\u001b[48;5;179m itself\u001b[48;5;185m,\u001b[48;5;77m because\u001b[48;5;80m it\u001b[48;5;134m is\u001b[48;5;185m pleasure\u001b[48;5;80m,\u001b[48;5;68m but\u001b[48;5;185m because\u001b[48;5;77m those\u001b[48;5;185m who\u001b[48;5;134m do\u001b[48;5;185m no\u001b[48;5;68mt\u001b[48;5;134m \u001b[48;5;167mkn\u001b[48;5;185mow\u001b[48;5;80m how\u001b[48;5;179m to\u001b[48;5;80m pursu\u001b[48;5;77me\u001b[48;5;80m pleasure\u001b[48;5;134m \u001b[48;5;167mr\u001b[48;5;179mation\u001b[48;5;134mally\u001b[48;5;77m en\u001b[48;5;134mc\u001b[48;5;167mount\u001b[48;5;80mer\u001b[48;5;134m consequences\u001b[48;5;68m that\u001b[48;5;77m are\u001b[48;5;167m ex\u001b[48;5;77mt\u001b[48;5;80mre\u001b[48;5;134mme\u001b[48;5;179mly\u001b[48;5;77m pain\u001b[48;5;179mf\u001b[48;5;185mul\u001b[48;5;80m.\u001b[48;5;68m N\u001b[48;5;167mor\u001b[48;5;185m a\u001b[48;5;80mg\u001b[48;5;68main\u001b[48;5;179m is\u001b[48;5;80m there\u001b[48;5;77m any\u001b[48;5;167mon\u001b[48;5;185me\u001b[48;5;77m who\u001b[48;5;167m \u001b[48;5;179ml\u001b[48;5;185mov\u001b[48;5;80mes\u001b[48;5;134m or\u001b[48;5;185m pursu\u001b[48;5;179mes\u001b[48;5;77m or\u001b[48;5;134m desire\u001b[48;5;167ms\u001b[48;5;179m to\u001b[48;5;77m obtain\u001b[0m\n",
      "----------------------------------------\n",
      "The current most common pair is b' se\\xc3\\xa7' + b'il'\n",
      "So we made b' se\\xc3\\xa7il' our 600th token\n",
      "Now the first fifty words in our training data look like:\n",
      "\u001b[48;5;167m       \u001b[48;5;179m 3\u001b[48;5;185m.\u001b[48;5;77m3\u001b[48;5;80m.\u001b[48;5;68mUçuş\u001b[48;5;185m Görevinin\u001b[48;5;68m Kapsamı\u001b[48;5;134m:\u001b[48;5;167m\n",
      "\u001b[48;5;179mBelirlenen\u001b[48;5;80m alan\u001b[48;5;185m,\u001b[48;5;77m farklı\u001b[48;5;80m renk\u001b[48;5;179m,\u001b[48;5;185m boyut\u001b[48;5;179m ve\u001b[48;5;80m hacimlere\u001b[48;5;167m sahip\u001b[48;5;134m karton\u001b[48;5;167m ve\u001b[48;5;185m branda\u001b[48;5;77m gibi\u001b[48;5;167m materyallerden\u001b[48;5;179m dağ\u001b[48;5;68m,\u001b[48;5;134m deniz\u001b[48;5;68m ve\u001b[48;5;179m binaları\u001b[48;5;77m temsil\u001b[48;5;80m edecek\u001b[48;5;77m piramit\u001b[48;5;80m ve\u001b[48;5;167m küplerden\u001b[48;5;77m oluşturacağımız\u001b[48;5;68m 10\u001b[48;5;179m metre\u001b[48;5;167m genişliğinde\u001b[48;5;134m ve\u001b[48;5;185m 20\u001b[48;5;68m metre\u001b[48;5;80m uzunluğunda\u001b[48;5;185m olan\u001b[48;5;167m 3\u001b[48;5;185m farklı\u001b[48;5;77m şehir\u001b[48;5;179m modelini\u001b[48;5;77m içerecektir\u001b[48;5;179m.\u001b[48;5;185m Üç\u001b[48;5;68m şehrin\u001b[48;5;134m (\u001b[48;5;167mA\u001b[48;5;179m,\u001b[48;5;185m B\u001b[48;5;80m ve\u001b[48;5;167m C\u001b[48;5;185m Şehirleri\u001b[48;5;68m)\u001b[48;5;134m seçil\u001b[48;5;68mme\u001b[48;5;167msinin\u001b[48;5;68m n\u001b[48;5;167meden\u001b[48;5;80mi\u001b[48;5;68m,\u001b[48;5;134m harita\u001b[48;5;167mlandırma\u001b[48;5;179m yap\u001b[48;5;80mma\u001b[48;5;134m ve\u001b[48;5;185m görüntü\u001b[48;5;77m işleme\u001b[48;5;80m algoritma\u001b[48;5;134mlar\u001b[48;5;185mını\u001b[48;5;68m ç\u001b[48;5;167mal\u001b[48;5;185mış\u001b[48;5;80mtır\u001b[48;5;167mma\u001b[48;5;185m ye\u001b[48;5;68mten\u001b[48;5;179me\u001b[48;5;185mğ\u001b[48;5;77mimiz\u001b[48;5;167mi\u001b[48;5;179m kan\u001b[48;5;68mı\u001b[48;5;134mt\u001b[48;5;167mla\u001b[48;5;185mma\u001b[48;5;80mk\u001b[48;5;68m için\u001b[48;5;77m yeterli\u001b[48;5;80m olduğunu\u001b[48;5;134m d\u001b[48;5;179mü\u001b[48;5;185mş\u001b[48;5;77mü\u001b[48;5;80mn\u001b[48;5;68mme\u001b[48;5;167mm\u001b[48;5;179miz\u001b[48;5;77md\u001b[48;5;80mir\u001b[48;5;134m.\u001b[48;5;167m Şehir\u001b[48;5;134m s\u001b[48;5;179mayı\u001b[48;5;80msı\u001b[48;5;134m \u001b[48;5;167mar\u001b[48;5;185mt\u001b[48;5;77mtır\u001b[48;5;134mı\u001b[48;5;167mla\u001b[48;5;185mb\u001b[48;5;77mil\u001b[48;5;68mir\u001b[48;5;167m f\u001b[48;5;185mak\u001b[48;5;80mat\u001b[48;5;134m b\u001b[48;5;179miz\u001b[48;5;77m görev\u001b[48;5;185mimiz\u001b[48;5;134m için\u001b[48;5;80m ü\u001b[48;5;134mç\u001b[48;5;167m şehrin\u001b[48;5;179m yeterli\u001b[48;5;185m olduğun\u001b[48;5;77ma\u001b[48;5;80m kanaat\u001b[48;5;77m getirdik\u001b[48;5;68m.\u001b[48;5;134m \u001b[48;5;167mİ\u001b[48;5;179mH\u001b[48;5;185mA\u001b[48;5;77m E\u001b[48;5;68mb\u001b[48;5;134mab\u001b[48;5;179mil\u001b[48;5;77m,\u001b[48;5;80m b\u001b[48;5;134maşlangıç\u001b[48;5;167m noktasından\u001b[48;5;68m otonom\u001b[48;5;134m o\u001b[48;5;167mlar\u001b[48;5;77mak\u001b[48;5;68m kalkış\u001b[48;5;134m yapacaktır\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train a BPE tokeniser on a small amount of text\n",
    "enc = train_simple_encoding()\n",
    "\n",
    "# Visualise how the GPT-4 encoder encodes text on both english and turkish\n",
    "# note this is just a simple implementation of how tiktoken actually works, there is some byte shifting stuff too\n",
    "# I have some trouble using the tiktoken library, so port the `_educational` version locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a7da5b-a2a4-4f21-903d-6dbcc1e4dfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('onlar',\n",
       " dict_keys(['protectedWords', 'vowelHarmonyExceptions', 'lastConsonantExceptions', 'averageStemSizeExceptions']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = TurkishStemmer()\n",
    "\n",
    "\"\"\"\n",
    "split the text into words based on the Turkish Stemmer library\n",
    "NOTE: doesn't work as expected, apparently it just derives the root of the word\n",
    "\"\"\"\n",
    "splitter.stem(\"onlarındakilerden\"), splitter.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfc2702-c3eb-4065-bf67-78f3f2f0ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;167mThe\u001b[48;5;77mquick\u001b[48;5;179mbrown\u001b[48;5;134mfox\u001b[48;5;185mjumped\u001b[48;5;179mover\u001b[48;5;68mthe\u001b[48;5;179mlazy\u001b[48;5;68mdog\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def _visualize(word):\n",
    "    return visualise_tokens(list(c.encode('utf-8') for c in word))\n",
    "_visualize(\"The quick brown fox jumped over the lazy dog\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9db0414-43cb-45af-b9c7-77aac017f0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;167mon\u001b[48;5;185mların\u001b[48;5;167mda\u001b[48;5;185mki\u001b[48;5;80mler\u001b[48;5;167mden\u001b[0m\n",
      "\u001b[48;5;167msokak\u001b[48;5;68mlar\u001b[48;5;179mda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "_visualize(turkish_word_splitter(\"onlarındakilerden\"))\n",
    "_visualize(turkish_word_splitter(\"sokaklarda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be86acd1-9caf-42c8-805f-951f361c15b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- TURKISH WORD TOKENS ---------------------\n",
      "        3.3.Uçuş Görevinin Kapsamı:\n",
      "Belirlenen alan, farklı renk, boyut ve hacimlere sahip karton ve branda gibi materyallerden dağ, deniz ve binaları temsil edecek piramit ve küplerden oluşturacağımız 10 metre genişliğinde ve 20 metre uzunluğunda olan 3 farklı şehir modelini içerecektir. Üç şehrin (A, B ve C Şehirleri) seçilmesinin nedeni, haritalandırma yapma ve görüntü işleme algoritmalarını çalıştırma yeteneğimizi kanıtlamak için yeterli olduğunu düşünmemizdir. Şehir sayısı arttırılabilir fakat biz görevimiz için üç şehrin yeterli olduğuna kanaat getirdik. İHA Ebabil, başlangıç noktasından otonom olarak kalkış yapacaktır. Başlangıç noktasından kalkış yaptıktan sonra A şehri üzerindeyken GPS bağlantısı kesilecek ve belirlenen görev doğrultusunda GPS'siz bir şekilde C şehrine gitmesi beklenecektir. A şehrinde GPS bağlantısı kesildiğinde, belirli bir yüksekliğe çıkarak şehri haritalayacak ve önceden tanımlanmış olan 3 şehir haritasından hangisinin doğru hedef olduğunu algılayacaktır. \n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*21, \"TURKISH WORD TOKENS\", \"-\"*21)\n",
    "with open(\"assets/tr_sample.txt\", \"r\") as f:\n",
    "    w = f.read()\n",
    "    print(w[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11c0b3ce-ee1b-4aa6-b141-1909b2b596eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' olduğunu', ' düşünmemiz', 'dir', '.', ' Şehir', ' sayısı', ' arttırılabilir', ' fakat', ' biz', ' görev', 'imiz', ' için', ' üç', ' şehrin', ' yeterli', ' olduğuna', ' kanaat', ' getirdik', '.', ' İHA', ' Ebabil', ',', ' başlangıç', ' noktasından', ' otonom', ' olarak', ' kalkış', ' yapacaktır', '.', ' Başlangıç', ' noktasından', ' kalkış', ' yaptıktan', ' sonra', ' A', ' şehri', ' üzerindeyken', ' GPS', ' bağlantısı', ' kesil', 'ecek', ' ve', ' belirlenen', ' görev', ' doğrultusunda', ' GPS', \"'siz\", ' bir', ' şekilde', ' C', ' şehrine', ' gitmesi', ' beklenecektir', '.', ' A', ' şehrinde', ' GPS', ' bağlantısı', ' kesildiğ', 'in', 'de', ',', ' belirli', ' bir', ' yüksekliğ', 'e', ' çıkarak', ' şehri', ' haritalay', 'acak', ' ve', ' önceden', ' tanımlanmış', ' olan', ' ', '3', ' şehir', ' haritas', 'ın', 'dan', ' hangis', 'in', 'in', ' doğru', ' hedef', ' olduğunu', ' algılayacaktır', '.', ' Haritalandırm', 'a', ' ve', ' görüntü', ' işleme', ' algoritmalarıyl', 'a', ' A', ' şehrinin', ' doğru', ' hedef', ' olmadığına', ' kanaat', ' getirdik', 'ten', ' sonra', ' B', ' şehrine', ' doğru', ' hareket', ' edecek', ' ve', ' aynı', ' prosedür', 'ü', ' uygulayarak', ' B', ' şehrinin', ' de', ' doğru', ' hedef', ' olmadığını', ' belirleyecektir', '.', ' Ardından', ',', ' C', ' şehrine', ' doğru', ' hareket', ' edecek', ' ve', ' burayı', ' da', ' haritalayıp', ' doğru', ' hedefe', ' ulaştığını', ' algılayarak', ' iniş', ' yapacaktır', '.', ' Bu', ' süreç', ',', ' tamamen', ' otonom', ' bir', ' şekilde', ' gerçekleşecek', ' olup', ',', ' insan', ' müdahalesi', ' olmayacaktır', '.\\n\\n', '5', '.BÜTÇE', ' VERİLERİ', ':\\n\\n', '5', '.', '1', '.Bütç', 'e', ' Tablos', 'u', ':\\n', ' ', ' Proje', ' bağlamında', ' talep', ' edilen', ' malzeme', ' ve', ' hizmetler', ' için', ' bütçe', ' detayları', ' Tablo', ' ', '3', '’', 'te', ' verilmiştir', '.\\n', '          ', ' Tablo', ' ', '3', '.', ' Proj', 'e', 'de', ' Talep', ' Edilen', ' Malzeme', ' ve', ' Hizmetler', ' için', ' Bütçe', ' Detay', 'lar', 'ı', '\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "words = turkish_split(w)\n",
    "print(words[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee569207-9571-478f-89b2-99c4f6920813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- TURKISH TOKENS ---------------------\n",
      "\u001b[48;5;167m       \u001b[48;5;179m \u001b[48;5;185m3\u001b[48;5;77m.\u001b[48;5;80m3\u001b[48;5;68m.Uçuş\u001b[48;5;185m Görev\u001b[48;5;179min\u001b[48;5;77min\u001b[48;5;68m Kapsam\u001b[48;5;134mı\u001b[48;5;167m:\n",
      "\u001b[48;5;179mBelirlenen\u001b[48;5;80m alan\u001b[48;5;185m,\u001b[48;5;77m farklı\u001b[48;5;80m renk\u001b[48;5;179m,\u001b[48;5;185m boyut\u001b[48;5;179m ve\u001b[48;5;80m hac\u001b[48;5;179mim\u001b[48;5;77mler\u001b[48;5;134me\u001b[48;5;167m sahip\u001b[48;5;134m karton\u001b[48;5;167m ve\u001b[48;5;185m bran\u001b[48;5;167mda\u001b[48;5;185m gibi\u001b[48;5;167m materyal\u001b[48;5;185mler\u001b[48;5;68mden\u001b[48;5;179m dağ\u001b[48;5;68m,\u001b[48;5;134m deniz\u001b[48;5;68m ve\u001b[48;5;179m binaları\u001b[48;5;77m temsil\u001b[48;5;80m edecek\u001b[48;5;77m piramit\u001b[48;5;80m ve\u001b[48;5;167m küp\u001b[48;5;80mler\u001b[48;5;167mden\u001b[48;5;77m oluşturacağ\u001b[48;5;179mımız\u001b[48;5;68m \u001b[48;5;134m10\u001b[48;5;179m metre\u001b[48;5;167m genişliğ\u001b[48;5;185min\u001b[48;5;80mde\u001b[48;5;134m ve\u001b[48;5;185m \u001b[48;5;77m20\u001b[48;5;68m metre\u001b[48;5;80m uzunluğunda\u001b[48;5;185m olan\u001b[48;5;167m \u001b[48;5;179m3\u001b[48;5;185m farklı\u001b[48;5;77m şehir\u001b[48;5;179m modelini\u001b[48;5;77m içerecektir\u001b[48;5;179m.\u001b[48;5;185m Üç\u001b[48;5;68m şehrin\u001b[48;5;134m (\u001b[48;5;167mA\u001b[48;5;179m,\u001b[48;5;185m B\u001b[48;5;80m ve\u001b[48;5;167m C\u001b[48;5;185m Şehir\u001b[48;5;179mler\u001b[48;5;80mi\u001b[48;5;68m)\u001b[48;5;134m seçilmes\u001b[48;5;179min\u001b[48;5;77min\u001b[48;5;68m nedeni\u001b[48;5;134m,\u001b[48;5;167m haritalandırm\u001b[48;5;134ma\u001b[48;5;167m yapma\u001b[48;5;134m ve\u001b[48;5;185m görüntü\u001b[48;5;77m işleme\u001b[48;5;80m algoritm\u001b[48;5;68ma\u001b[48;5;134mların\u001b[48;5;80mı\u001b[48;5;68m çalıştırma\u001b[48;5;185m yeteneğ\u001b[48;5;77mimiz\u001b[48;5;167mi\u001b[48;5;179m kanıtlamak\u001b[48;5;68m için\u001b[48;5;77m yeterli\u001b[48;5;80m olduğunu\u001b[48;5;134m düşünmemiz\u001b[48;5;77mdir\u001b[48;5;134m.\u001b[48;5;167m Şehir\u001b[48;5;134m sayısı\u001b[48;5;167m arttırılabilir\u001b[48;5;179m fakat\u001b[48;5;134m biz\u001b[48;5;77m görev\u001b[48;5;185mimiz\u001b[48;5;134m için\u001b[48;5;80m üç\u001b[48;5;167m şehrin\u001b[48;5;179m yeterli\u001b[48;5;185m olduğuna\u001b[48;5;77m kanaat\u001b[48;5;80m getirdik\u001b[48;5;68m.\u001b[48;5;134m İHA\u001b[48;5;77m Ebabil\u001b[48;5;80m,\u001b[48;5;68m başlangıç\u001b[48;5;167m noktasından\u001b[48;5;68m otonom\u001b[48;5;134m olarak\u001b[48;5;68m kalkış\u001b[48;5;134m yapacaktır\u001b[48;5;185m.\u001b[48;5;77m Başlangıç\u001b[48;5;134m noktasından\u001b[48;5;80m kalkış\u001b[48;5;68m yaptıktan\u001b[48;5;167m sonra\u001b[48;5;134m A\u001b[48;5;179m şehri\u001b[48;5;167m üzerindeyken\u001b[48;5;134m GPS\u001b[48;5;77m bağlantısı\u001b[48;5;167m kesil\u001b[48;5;134mecek\u001b[48;5;77m ve\u001b[48;5;134m belirlenen\u001b[48;5;77m görev\u001b[48;5;185m doğrultusunda\u001b[48;5;77m GPS\u001b[48;5;134m'siz\u001b[48;5;77m bir\u001b[48;5;167m şekilde\u001b[48;5;179m C\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*21, \"TURKISH TOKENS\", \"-\"*21)\n",
    "_visualize(words[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d21d5d2-d6eb-4ab4-ac92-1c413678b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "['Minicik', ' kuşlar', ' minar', 'e', 'de', ' öter', 'ler', ',', ' minar', 'e', 'de', ' öterlers', 'e', ' minar', 'e', 'de', ' niçin', ' öter', 'ler', '?']\n",
      "--------\n",
      "\u001b[48;5;167mMinicik\u001b[48;5;179m kuşlar\u001b[48;5;167m minar\u001b[48;5;134me\u001b[48;5;167mde\u001b[48;5;185m öter\u001b[48;5;167mler\u001b[48;5;77m,\u001b[48;5;80m minar\u001b[48;5;77me\u001b[48;5;80mde\u001b[48;5;134m öterlers\u001b[48;5;179me\u001b[48;5;185m minar\u001b[48;5;179me\u001b[48;5;185mde\u001b[48;5;80m niçin\u001b[48;5;77m öter\u001b[48;5;179mler\u001b[48;5;80m?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "s = turkish_split(\"Minicik kuşlar minarede öterler, minarede öterlerse minarede niçin öterler?\")\n",
    "print(\"-\"*8)\n",
    "print(s)\n",
    "print(\"-\"*8)\n",
    "_visualize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd87272-5fd9-4348-9980-5b258a0bc72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "['Bir', ' ', 'b', 'e', 'r', 'b', 'e', 'r', ' bir', ' ', 'b', 'e', 'r', 'b', 'e', 'r', 'e', ' gel', ' beraber', ' bir', ' ', 'b', 'e', 'r', 'b', 'e', 'r', ' dükkanı', ' ', 'a', 'ç', 'a', 'l', 'ım', ' demiş']\n",
      "--------\n",
      "\u001b[48;5;167mBir\u001b[48;5;77m \u001b[48;5;80mb\u001b[48;5;68me\u001b[48;5;134mr\u001b[48;5;167mb\u001b[48;5;179me\u001b[48;5;185mr\u001b[48;5;77m bir\u001b[48;5;167m \u001b[48;5;179mb\u001b[48;5;185me\u001b[48;5;77mr\u001b[48;5;80mb\u001b[48;5;68me\u001b[48;5;134mr\u001b[48;5;167me\u001b[48;5;179m gel\u001b[48;5;68m beraber\u001b[48;5;134m bir\u001b[48;5;77m \u001b[48;5;80mb\u001b[48;5;68me\u001b[48;5;134mr\u001b[48;5;167mb\u001b[48;5;179me\u001b[48;5;185mr\u001b[48;5;77m dükkanı\u001b[48;5;80m \u001b[48;5;68ma\u001b[48;5;134mç\u001b[48;5;167ma\u001b[48;5;179ml\u001b[48;5;185mım\u001b[48;5;80m demiş\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "s = turkish_split(\"Bir berber bir berbere gel beraber bir berber dükkanı açalım demiş\")\n",
    "print(\"-\"*8)\n",
    "print(s)\n",
    "print(\"-\"*8)\n",
    "_visualize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139f6f7-b2eb-4e94-b4ae-435cc09b2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There seems to be an issue currently in the last two cells. Not every turkish word is contained in the vocab.txt file fetched from BERT2-turkish-cased on hugging face. \n",
    "# So, we will create a train_bpe() so as to train our own vocabs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
